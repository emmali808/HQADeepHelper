{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingzhu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import random\n",
    "random.seed(49999)\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy\n",
    "numpy.random.seed(49999)\n",
    "import tensorflow\n",
    "tensorflow.set_random_seed(49999)\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import inputs\n",
    "import metrics\n",
    "from losses import *\n",
    "from optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tensorflow.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tensorflow.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('models/')\n",
    "\n",
    "from utils.utility import *\n",
    "from layers.Match import *\n",
    "\n",
    "class MVLSTM:\n",
    "    def __init__(self, config):\n",
    "        self.__name = 'MVLSTM'\n",
    "        self.config = {}\n",
    "        self.check_list = [ 'text1_maxlen', 'text2_maxlen',\n",
    "                   'embed', 'embed_size', 'train_embed',  'vocab_size',\n",
    "                   'hidden_size', 'topk', 'dropout_rate']\n",
    "        self.embed_trainable = config['train_embed']\n",
    "        self.setup(config)\n",
    "        if not self.check():\n",
    "            raise TypeError('[MVLSTM] parameter check wrong')\n",
    "        print('[MVLSTM] init done', end='\\n')\n",
    "        \n",
    "    def set_default(self, k, v):\n",
    "        if k not in self.config:\n",
    "            self.config[k] = v\n",
    "            \n",
    "    def check(self):\n",
    "        for e in self.check_list:\n",
    "            if e not in self.config:\n",
    "                print(e, end='\\n')\n",
    "                print('[Model] Error %s not in config' % e, end='\\n')\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def check_list(self,check_list):\n",
    "        self.check_list = check_list\n",
    "\n",
    "    def setup(self, config):\n",
    "        if not isinstance(config, dict):\n",
    "            raise TypeError('parameter config should be dict:', config)\n",
    "\n",
    "        self.set_default('hidden_size', 32)\n",
    "        self.set_default('topk', 100)\n",
    "        self.set_default('dropout_rate', 0)\n",
    "        self.config.update(config)\n",
    "\n",
    "    def build(self):\n",
    "        query = Input(name='query', shape=(self.config['text1_maxlen'],))\n",
    "        show_layer_info('Input', query)\n",
    "        doc = Input(name='doc', shape=(self.config['text2_maxlen'],))\n",
    "        show_layer_info('Input', doc)\n",
    "\n",
    "        embedding = Embedding(self.config['vocab_size'], self.config['embed_size'], weights=[self.config['embed']], trainable = self.embed_trainable)\n",
    "        q_embed = embedding(query)\n",
    "        show_layer_info('Embedding', q_embed)\n",
    "        d_embed = embedding(doc)\n",
    "        show_layer_info('Embedding', d_embed)\n",
    "\n",
    "        q_rep = Bidirectional(LSTM(self.config['hidden_size'], return_sequences=True, dropout=self.config['dropout_rate']))(q_embed)\n",
    "        show_layer_info('Bidirectional-LSTM', q_rep)\n",
    "        d_rep = Bidirectional(LSTM(self.config['hidden_size'], return_sequences=True, dropout=self.config['dropout_rate']))(d_embed)\n",
    "        show_layer_info('Bidirectional-LSTM', d_rep)\n",
    "\n",
    "        cross = Match(match_type='dot')([q_rep, d_rep])\n",
    "        #cross = Dot(axes=[2, 2])([q_embed, d_embed])\n",
    "        show_layer_info('Match-dot', cross)\n",
    "\n",
    "        cross_reshape = Reshape((-1, ))(cross)\n",
    "        show_layer_info('Reshape', cross_reshape)\n",
    "\n",
    "        mm_k = Lambda(lambda x: K.tf.nn.top_k(x, k=self.config['topk'], sorted=True)[0])(cross_reshape)\n",
    "        show_layer_info('Lambda-topk', mm_k)\n",
    "\n",
    "        pool1_flat_drop = Dropout(rate=self.config['dropout_rate'])(mm_k)\n",
    "        show_layer_info('Dropout', pool1_flat_drop)\n",
    "\n",
    "        if self.config['target_mode'] == 'classification':\n",
    "            out_ = Dense(2, activation='softmax')(pool1_flat_drop)\n",
    "        elif self.config['target_mode'] in ['regression', 'ranking']:\n",
    "            out_ = Dense(1)(pool1_flat_drop)\n",
    "        show_layer_info('Dense', out_)\n",
    "\n",
    "        #model = Model(inputs=[query, doc, dpool_index], outputs=out_)\n",
    "        model = Model(inputs=[query, doc], outputs=out_)\n",
    "        return model\n",
    "\n",
    "def load_model(config):\n",
    "    model_config = config['model']['setting']\n",
    "    model_config.update(config['inputs']['share'])\n",
    "    model = MVLSTM(model_config)\n",
    "    mo = model.build()\n",
    "    return mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "\n",
    "    print(json.dumps(config, indent=2), end='\\n')\n",
    "    # read basic config\n",
    "    global_conf = config[\"global\"]\n",
    "#     optimizer = global_conf['optimizer']\n",
    "#     optimizer = optimizers.get(optimizer)\n",
    "#     K.set_value(optimizer.lr, global_conf['learning_rate'])\n",
    "    weights_file = str(global_conf['weights_file']) + '.%d'\n",
    "    display_interval = int(global_conf['display_interval'])\n",
    "    num_iters = int(global_conf['num_iters'])\n",
    "    save_weights_iters = int(global_conf['save_weights_iters'])\n",
    "\n",
    "    # read input config\n",
    "    input_conf = config['inputs']\n",
    "    share_input_conf = input_conf['share']\n",
    "\n",
    "\n",
    "    # collect embedding\n",
    "    if 'embed_path' in share_input_conf:\n",
    "        embed_dict = read_embedding(filename=share_input_conf['embed_path'])\n",
    "        _PAD_ = share_input_conf['vocab_size'] - 1\n",
    "        embed_dict[_PAD_] = np.zeros((share_input_conf['embed_size'], ), dtype=np.float32)\n",
    "        embed = np.float32(np.random.uniform(-0.2, 0.2, [share_input_conf['vocab_size'], share_input_conf['embed_size']]))\n",
    "        share_input_conf['embed'] = convert_embed_2_numpy(embed_dict, embed = embed)\n",
    "    else:\n",
    "        embed = np.float32(np.random.uniform(-0.2, 0.2, [share_input_conf['vocab_size'], share_input_conf['embed_size']]))\n",
    "        share_input_conf['embed'] = embed\n",
    "    print('[Embedding] Embedding Load Done.', end='\\n')\n",
    "\n",
    "    # list all input tags and construct tags config\n",
    "    input_train_conf = OrderedDict()\n",
    "    input_eval_conf = OrderedDict()\n",
    "    for tag in input_conf.keys():\n",
    "        if 'phase' not in input_conf[tag]:\n",
    "            continue\n",
    "        if input_conf[tag]['phase'] == 'TRAIN':\n",
    "            input_train_conf[tag] = {}\n",
    "            input_train_conf[tag].update(share_input_conf)\n",
    "            input_train_conf[tag].update(input_conf[tag])\n",
    "        elif input_conf[tag]['phase'] == 'EVAL':\n",
    "            input_eval_conf[tag] = {}\n",
    "            input_eval_conf[tag].update(share_input_conf)\n",
    "            input_eval_conf[tag].update(input_conf[tag])\n",
    "    print('[Input] Process Input Tags. %s in TRAIN, %s in EVAL.' % (input_train_conf.keys(), input_eval_conf.keys()), end='\\n')\n",
    "\n",
    "    # collect dataset identification\n",
    "    dataset = {}\n",
    "    for tag in input_conf:\n",
    "        if tag != 'share' and input_conf[tag]['phase'] == 'PREDICT':\n",
    "            continue\n",
    "        if 'text1_corpus' in input_conf[tag]:\n",
    "            datapath = input_conf[tag]['text1_corpus']\n",
    "            if datapath not in dataset:\n",
    "                dataset[datapath], _ = read_data(datapath)\n",
    "        if 'text2_corpus' in input_conf[tag]:\n",
    "            datapath = input_conf[tag]['text2_corpus']\n",
    "            if datapath not in dataset:\n",
    "                dataset[datapath], _ = read_data(datapath)\n",
    "    print('[Dataset] %s Dataset Load Done.' % len(dataset), end='\\n')\n",
    "\n",
    "    # initial data generator\n",
    "    train_gen = OrderedDict()\n",
    "    eval_gen = OrderedDict()\n",
    "\n",
    "    for tag, conf in input_train_conf.items():\n",
    "        print(conf, end='\\n')\n",
    "        conf['data1'] = dataset[conf['text1_corpus']]\n",
    "        conf['data2'] = dataset[conf['text2_corpus']]\n",
    "        generator = inputs.get(conf['input_type'])\n",
    "        train_gen[tag] = generator( config = conf )\n",
    "\n",
    "    for tag, conf in input_eval_conf.items():\n",
    "        print(conf, end='\\n')\n",
    "        conf['data1'] = dataset[conf['text1_corpus']]\n",
    "        conf['data2'] = dataset[conf['text2_corpus']]\n",
    "        generator = inputs.get(conf['input_type'])\n",
    "        eval_gen[tag] = generator( config = conf )\n",
    "\n",
    "    ######### Load Model #########\n",
    "    model = load_model(config)\n",
    "\n",
    "    loss = []\n",
    "    for lobj in config['losses']:\n",
    "        if lobj['object_name'] in mz_specialized_losses:\n",
    "            loss.append(rank_losses.get(lobj['object_name'])(lobj['object_params']))\n",
    "        else:\n",
    "            loss.append(rank_losses.get(lobj['object_name']))\n",
    "    eval_metrics = OrderedDict()\n",
    "    for mobj in config['metrics']:\n",
    "        mobj = mobj.lower()\n",
    "        if '@' in mobj:\n",
    "            mt_key, mt_val = mobj.split('@', 1)\n",
    "            eval_metrics[mobj] = metrics.get(mt_key)(int(mt_val))\n",
    "        else:\n",
    "            eval_metrics[mobj] = metrics.get(mobj)\n",
    "    optimizer = Adadelta(lr=config[\"global\"][\"learning_rate\"], rho=0.95)\n",
    "    model.compile(optimizer = optimizer, loss=loss)\n",
    "    print('[Model] Model Compile Done.', end='\\n')\n",
    "\n",
    "    for i_e in range(num_iters):\n",
    "        for tag, generator in train_gen.items():\n",
    "            genfun = generator.get_batch_generator()\n",
    "            print('[%s]\\t[Train:%s] ' % (time.strftime('%m-%d-%Y %H:%M:%S', time.localtime(time.time())), tag), end='')\n",
    "            history = model.fit_generator(\n",
    "                    genfun,\n",
    "                    steps_per_epoch = display_interval,\n",
    "                    epochs = 1,\n",
    "                    shuffle=False,\n",
    "                    verbose = 0\n",
    "                ) #callbacks=[eval_map])\n",
    "            print('Iter:%d\\tloss=%.6f' % (i_e, history.history['loss'][0]), end='\\n')\n",
    "\n",
    "#         for tag, generator in eval_gen.items():\n",
    "#             genfun = generator.get_batch_generator()\n",
    "#             print('[%s]\\t[Eval:%s] ' % (time.strftime('%m-%d-%Y %H:%M:%S', time.localtime(time.time())), tag), end='')\n",
    "#             res = dict([[k,0.] for k in eval_metrics.keys()])\n",
    "#             num_valid = 0\n",
    "#             for input_data, y_true in genfun:\n",
    "#                 y_pred = model.predict(input_data, batch_size=len(y_true))\n",
    "#                 if issubclass(type(generator), inputs.list_generator.ListBasicGenerator):\n",
    "#                     list_counts = input_data['list_counts']\n",
    "#                     for k, eval_func in eval_metrics.items():\n",
    "#                         for lc_idx in range(len(list_counts)-1):\n",
    "#                             pre = list_counts[lc_idx]\n",
    "#                             suf = list_counts[lc_idx+1]\n",
    "#                             res[k] += eval_func(y_true = y_true[pre:suf], y_pred = y_pred[pre:suf])\n",
    "#                     num_valid += len(list_counts) - 1\n",
    "#                 else:\n",
    "#                     for k, eval_func in eval_metrics.items():\n",
    "#                         res[k] += eval_func(y_true = y_true, y_pred = y_pred)\n",
    "#                     num_valid += 1\n",
    "#             generator.reset()\n",
    "#             print('Iter:%d\\t%s' % (i_e, '\\t'.join(['%s=%f'%(k,v/num_valid) for k, v in res.items()])), end='\\n')\n",
    "#             sys.stdout.flush()\n",
    "#         if (i_e+1) % save_weights_iters == 0:\n",
    "#             model.save_weights(weights_file % (i_e+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"net_name\": \"MVLSTM\",\n",
    "  \"global\":{\n",
    "      \"model_type\": \"PY\",\n",
    "      \"weights_file\": \"../examples/wikiqa/weights/mvlstm.wikiqa.weights\",\n",
    "      \"save_weights_iters\": 10,\n",
    "      \"num_iters\": 400,\n",
    "      \"display_interval\": 10,\n",
    "      \"test_weights_iters\": 400,\n",
    "      \"optimizer\": \"adadelta\",\n",
    "      \"learning_rate\": 1.0\n",
    "  },\n",
    "  \"inputs\": {\n",
    "    \"share\": {\n",
    "        \"text1_corpus\": \"../data/WikiQA/corpus_preprocessed.txt\",\n",
    "        \"text2_corpus\": \"../data/WikiQA/corpus_preprocessed.txt\",\n",
    "        \"use_dpool\": False,\n",
    "        \"embed_size\": 50,\n",
    "        \"embed_path\": \"../data/WikiQA/embed_glove_d50\",\n",
    "        \"vocab_size\": 18670,\n",
    "        \"train_embed\": False,\n",
    "        \"target_mode\": \"ranking\",\n",
    "        \"text1_maxlen\": 10,\n",
    "        \"text2_maxlen\": 40\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"input_type\": \"PairGenerator\", \n",
    "        \"phase\": \"TRAIN\",\n",
    "        \"use_iter\": False,\n",
    "        \"query_per_iter\": 50,\n",
    "        \"batch_per_iter\": 5,\n",
    "        \"batch_size\": 100,\n",
    "        \"relation_file\": \"../data/WikiQA/relation_train.txt\"\n",
    "    },\n",
    "    \"valid\": {\n",
    "        \"input_type\": \"ListGenerator\", \n",
    "        \"phase\": \"EVAL\",\n",
    "        \"batch_list\": 10,\n",
    "        \"relation_file\": \"../data/WikiQA/relation_valid.txt\"\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"input_type\": \"ListGenerator\", \n",
    "        \"phase\": \"EVAL\",\n",
    "        \"batch_list\": 10,\n",
    "        \"relation_file\": \"../data/WikiQA/relation_test.txt\"\n",
    "    },\n",
    "    \"predict\": {\n",
    "        \"input_type\": \"ListGenerator\", \n",
    "        \"phase\": \"PREDICT\",\n",
    "        \"batch_list\": 10,\n",
    "        \"relation_file\": \"../data/WikiQA/relation_test.txt\"\n",
    "    }\n",
    "  },\n",
    "  \"outputs\": {\n",
    "    \"predict\": {\n",
    "      \"save_format\": \"TREC\",\n",
    "      \"save_path\": \"predict.test.mvlstm.wikiqa.txt\"\n",
    "    }\n",
    "  },\n",
    "  \"model\": {\n",
    "    \"model_path\": \"models/\",\n",
    "    \"model_py\": \"mvlstm.MVLSTM\",\n",
    "    \"setting\": {\n",
    "        \"hidden_size\": 50,\n",
    "        \"topk\": 100,\n",
    "        \"dropout_rate\": 0.5\n",
    "    }\n",
    "  },\n",
    "  \"losses\": [ \n",
    "    {\n",
    "       \"object_name\": \"rank_hinge_loss\" ,\n",
    "       \"object_params\": {\n",
    "            \"margin\": 1.0\n",
    "       }\n",
    "    }\n",
    "  ],\n",
    "  \"metrics\": [ \"ndcg@3\", \"ndcg@5\", \"map\" ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"inputs\": {\n",
      "    \"test\": {\n",
      "      \"phase\": \"EVAL\", \n",
      "      \"input_type\": \"ListGenerator\", \n",
      "      \"relation_file\": \"../data/WikiQA/relation_test.txt\", \n",
      "      \"batch_list\": 10\n",
      "    }, \n",
      "    \"predict\": {\n",
      "      \"phase\": \"PREDICT\", \n",
      "      \"input_type\": \"ListGenerator\", \n",
      "      \"relation_file\": \"../data/WikiQA/relation_test.txt\", \n",
      "      \"batch_list\": 10\n",
      "    }, \n",
      "    \"train\": {\n",
      "      \"relation_file\": \"../data/WikiQA/relation_train.txt\", \n",
      "      \"input_type\": \"PairGenerator\", \n",
      "      \"batch_size\": 100, \n",
      "      \"batch_per_iter\": 5, \n",
      "      \"phase\": \"TRAIN\", \n",
      "      \"query_per_iter\": 50, \n",
      "      \"use_iter\": false\n",
      "    }, \n",
      "    \"share\": {\n",
      "      \"text2_corpus\": \"../data/WikiQA/corpus_preprocessed.txt\", \n",
      "      \"vocab_size\": 18670, \n",
      "      \"use_dpool\": false, \n",
      "      \"embed_path\": \"../data/WikiQA/embed_glove_d50\", \n",
      "      \"text1_maxlen\": 10, \n",
      "      \"embed_size\": 50, \n",
      "      \"target_mode\": \"ranking\", \n",
      "      \"train_embed\": false, \n",
      "      \"text1_corpus\": \"../data/WikiQA/corpus_preprocessed.txt\", \n",
      "      \"text2_maxlen\": 40\n",
      "    }, \n",
      "    \"valid\": {\n",
      "      \"phase\": \"EVAL\", \n",
      "      \"input_type\": \"ListGenerator\", \n",
      "      \"relation_file\": \"../data/WikiQA/relation_valid.txt\", \n",
      "      \"batch_list\": 10\n",
      "    }\n",
      "  }, \n",
      "  \"global\": {\n",
      "    \"weights_file\": \"../examples/wikiqa/weights/mvlstm.wikiqa.weights\", \n",
      "    \"optimizer\": \"adadelta\", \n",
      "    \"num_iters\": 400, \n",
      "    \"save_weights_iters\": 10, \n",
      "    \"model_type\": \"PY\", \n",
      "    \"learning_rate\": 1.0, \n",
      "    \"test_weights_iters\": 400, \n",
      "    \"display_interval\": 10\n",
      "  }, \n",
      "  \"outputs\": {\n",
      "    \"predict\": {\n",
      "      \"save_format\": \"TREC\", \n",
      "      \"save_path\": \"predict.test.mvlstm.wikiqa.txt\"\n",
      "    }\n",
      "  }, \n",
      "  \"losses\": [\n",
      "    {\n",
      "      \"object_name\": \"rank_hinge_loss\", \n",
      "      \"object_params\": {\n",
      "        \"margin\": 1.0\n",
      "      }\n",
      "    }\n",
      "  ], \n",
      "  \"metrics\": [\n",
      "    \"ndcg@3\", \n",
      "    \"ndcg@5\", \n",
      "    \"map\"\n",
      "  ], \n",
      "  \"net_name\": \"MVLSTM\", \n",
      "  \"model\": {\n",
      "    \"model_py\": \"mvlstm.MVLSTM\", \n",
      "    \"setting\": {\n",
      "      \"dropout_rate\": 0.5, \n",
      "      \"hidden_size\": 50, \n",
      "      \"topk\": 100\n",
      "    }, \n",
      "    \"model_path\": \"models/\"\n",
      "  }\n",
      "}\n",
      "[../data/WikiQA/embed_glove_d50]\n",
      "\tEmbedding size: 18670\n",
      "Generate numpy embed: (18670, 50)\n",
      "[Embedding] Embedding Load Done.\n",
      "[Input] Process Input Tags. ['train'] in TRAIN, ['test', 'valid'] in EVAL.\n",
      "[../data/WikiQA/corpus_preprocessed.txt]\n",
      "\tData size: 24106\n",
      "[Dataset] 1 Dataset Load Done.\n",
      "{'relation_file': '../data/WikiQA/relation_train.txt', 'vocab_size': 18670, 'query_per_iter': 50, 'use_dpool': False, 'embed_size': 50, 'target_mode': 'ranking', 'input_type': 'PairGenerator', 'text1_corpus': '../data/WikiQA/corpus_preprocessed.txt', 'batch_size': 100, 'batch_per_iter': 5, 'text2_corpus': '../data/WikiQA/corpus_preprocessed.txt', 'embed_path': '../data/WikiQA/embed_glove_d50', 'text1_maxlen': 10, 'phase': 'TRAIN', 'embed': array([[ 5.3201002e-01,  1.0601000e-02,  1.4717001e-01, ...,\n",
      "         1.3226000e+00,  1.1690000e-01,  6.2825002e-02],\n",
      "       [-1.0386000e+00,  5.2319998e-01, -7.3141003e-01, ...,\n",
      "         1.8791001e-01, -2.4800999e-02,  4.2411000e-01],\n",
      "       [-9.5642000e-01, -1.0021000e+00, -3.7779000e-01, ...,\n",
      "         1.7704000e-01,  4.1834000e-01,  9.7698998e-01],\n",
      "       ...,\n",
      "       [-1.6011000e-01, -8.2514000e-01, -9.9243000e-02, ...,\n",
      "        -5.3280002e-01, -1.0692000e+00,  7.0389003e-01],\n",
      "       [-7.5430633e-04,  6.7681572e-03, -9.8872548e-03, ...,\n",
      "         3.6578432e-02, -2.6922885e-02,  1.0013765e-02],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32), 'text2_maxlen': 40, 'train_embed': False, 'use_iter': False}\n",
      "[../data/WikiQA/relation_train.txt]\n",
      "\tInstance size: 20360\n",
      "Pair Instance Count: 8995\n",
      "[PairGenerator] init done\n",
      "{'relation_file': '../data/WikiQA/relation_test.txt', 'vocab_size': 18670, 'use_dpool': False, 'embed_size': 50, 'target_mode': 'ranking', 'input_type': 'ListGenerator', 'batch_list': 10, 'text1_corpus': '../data/WikiQA/corpus_preprocessed.txt', 'text2_corpus': '../data/WikiQA/corpus_preprocessed.txt', 'embed_path': '../data/WikiQA/embed_glove_d50', 'text1_maxlen': 10, 'phase': 'EVAL', 'embed': array([[ 5.3201002e-01,  1.0601000e-02,  1.4717001e-01, ...,\n",
      "         1.3226000e+00,  1.1690000e-01,  6.2825002e-02],\n",
      "       [-1.0386000e+00,  5.2319998e-01, -7.3141003e-01, ...,\n",
      "         1.8791001e-01, -2.4800999e-02,  4.2411000e-01],\n",
      "       [-9.5642000e-01, -1.0021000e+00, -3.7779000e-01, ...,\n",
      "         1.7704000e-01,  4.1834000e-01,  9.7698998e-01],\n",
      "       ...,\n",
      "       [-1.6011000e-01, -8.2514000e-01, -9.9243000e-02, ...,\n",
      "        -5.3280002e-01, -1.0692000e+00,  7.0389003e-01],\n",
      "       [-7.5430633e-04,  6.7681572e-03, -9.8872548e-03, ...,\n",
      "         3.6578432e-02, -2.6922885e-02,  1.0013765e-02],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32), 'text2_maxlen': 40, 'train_embed': False}\n",
      "[../data/WikiQA/relation_test.txt]\n",
      "\tInstance size: 2341\n",
      "List Instance Count: 237\n",
      "[ListGenerator] init done\n",
      "{'relation_file': '../data/WikiQA/relation_valid.txt', 'vocab_size': 18670, 'use_dpool': False, 'embed_size': 50, 'target_mode': 'ranking', 'input_type': 'ListGenerator', 'batch_list': 10, 'text1_corpus': '../data/WikiQA/corpus_preprocessed.txt', 'text2_corpus': '../data/WikiQA/corpus_preprocessed.txt', 'embed_path': '../data/WikiQA/embed_glove_d50', 'text1_maxlen': 10, 'phase': 'EVAL', 'embed': array([[ 5.3201002e-01,  1.0601000e-02,  1.4717001e-01, ...,\n",
      "         1.3226000e+00,  1.1690000e-01,  6.2825002e-02],\n",
      "       [-1.0386000e+00,  5.2319998e-01, -7.3141003e-01, ...,\n",
      "         1.8791001e-01, -2.4800999e-02,  4.2411000e-01],\n",
      "       [-9.5642000e-01, -1.0021000e+00, -3.7779000e-01, ...,\n",
      "         1.7704000e-01,  4.1834000e-01,  9.7698998e-01],\n",
      "       ...,\n",
      "       [-1.6011000e-01, -8.2514000e-01, -9.9243000e-02, ...,\n",
      "        -5.3280002e-01, -1.0692000e+00,  7.0389003e-01],\n",
      "       [-7.5430633e-04,  6.7681572e-03, -9.8872548e-03, ...,\n",
      "         3.6578432e-02, -2.6922885e-02,  1.0013765e-02],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32), 'text2_maxlen': 40, 'train_embed': False}\n",
      "[../data/WikiQA/relation_valid.txt]\n",
      "\tInstance size: 1126\n",
      "List Instance Count: 122\n",
      "[ListGenerator] init done\n",
      "[MVLSTM] init done\n",
      "[layer]: Input\t[shape]: [None, 10] \n",
      "2.6% memory has been used\n",
      "[layer]: Input\t[shape]: [None, 40] \n",
      "2.6% memory has been used\n",
      "[layer]: Embedding\t[shape]: [None, 10, 50] \n",
      "2.6% memory has been used\n",
      "[layer]: Embedding\t[shape]: [None, 40, 50] \n",
      "2.6% memory has been used\n",
      "[layer]: Bidirectional-LSTM\t[shape]: [None, None, 100] \n",
      "2.6% memory has been used\n",
      "[layer]: Bidirectional-LSTM\t[shape]: [None, None, 100] \n",
      "2.7% memory has been used\n",
      "[layer]: Match-dot\t[shape]: [None, None, None, 1] \n",
      "2.7% memory has been used\n",
      "[layer]: Reshape\t[shape]: [None, None] \n",
      "2.7% memory has been used\n",
      "[layer]: Lambda-topk\t[shape]: [None, 100] \n",
      "2.7% memory has been used\n",
      "[layer]: Dropout\t[shape]: [None, 100] \n",
      "2.7% memory has been used\n",
      "[layer]: Dense\t[shape]: [None, 1] \n",
      "2.7% memory has been used\n",
      "[Model] Model Compile Done.\n",
      "[02-04-2019 18:33:12]\t[Train:train] Iter:0\tloss=0.971602\n",
      "[02-04-2019 18:33:20]\t[Train:train] Iter:1\tloss=0.942797\n",
      "[02-04-2019 18:33:22]\t[Train:train] Iter:2\tloss=0.970714\n",
      "[02-04-2019 18:33:24]\t[Train:train] Iter:3\tloss=0.937743\n",
      "[02-04-2019 18:33:26]\t[Train:train] Iter:4\tloss=0.843464\n",
      "[02-04-2019 18:33:28]\t[Train:train] Iter:5\tloss=0.824024\n",
      "[02-04-2019 18:33:31]\t[Train:train] Iter:6\tloss=0.827944\n",
      "[02-04-2019 18:33:33]\t[Train:train] Iter:7\tloss=0.772310\n",
      "[02-04-2019 18:33:35]\t[Train:train] Iter:8\tloss=0.744457\n",
      "[02-04-2019 18:33:37]\t[Train:train] Iter:9\tloss=0.750221\n",
      "[02-04-2019 18:33:39]\t[Train:train] Iter:10\tloss=0.740050\n",
      "[02-04-2019 18:33:41]\t[Train:train] Iter:11\tloss=0.741391\n",
      "[02-04-2019 18:33:44]\t[Train:train] Iter:12\tloss=0.712712\n",
      "[02-04-2019 18:33:46]\t[Train:train] Iter:13\tloss=0.679865\n",
      "[02-04-2019 18:33:48]\t[Train:train] Iter:14\tloss=0.716155\n",
      "[02-04-2019 18:33:50]\t[Train:train] Iter:15\tloss=0.704108\n",
      "[02-04-2019 18:33:52]\t[Train:train] Iter:16\tloss=0.687565\n",
      "[02-04-2019 18:33:54]\t[Train:train] Iter:17\tloss=0.736957\n",
      "[02-04-2019 18:33:56]\t[Train:train] Iter:18\tloss=0.711970\n",
      "[02-04-2019 18:33:58]\t[Train:train] Iter:19\tloss=0.708483\n",
      "[02-04-2019 18:34:01]\t[Train:train] Iter:20\tloss=0.690346\n",
      "[02-04-2019 18:34:03]\t[Train:train] Iter:21\tloss=0.649918\n",
      "[02-04-2019 18:34:05]\t[Train:train] Iter:22\tloss=0.697421\n",
      "[02-04-2019 18:34:07]\t[Train:train] Iter:23\tloss=0.667694\n",
      "[02-04-2019 18:34:09]\t[Train:train] Iter:24\tloss=0.656876\n",
      "[02-04-2019 18:34:11]\t[Train:train] Iter:25\tloss=0.660078\n",
      "[02-04-2019 18:34:13]\t[Train:train] Iter:26\tloss=0.650242\n",
      "[02-04-2019 18:34:15]\t[Train:train] Iter:27\tloss=0.678583\n",
      "[02-04-2019 18:34:18]\t[Train:train] Iter:28\tloss=0.688267\n",
      "[02-04-2019 18:34:20]\t[Train:train] "
     ]
    }
   ],
   "source": [
    "phase = 'train'\n",
    "# model_file = '../examples/wikiqa/config/mvlstm_wikiqa.config'\n",
    "# with open(model_file, 'r') as f:\n",
    "#     config = json.load(f)\n",
    "    \n",
    "if phase == 'train':\n",
    "    train(config)\n",
    "elif phase == 'predict':\n",
    "    predict(config)\n",
    "else:\n",
    "    print('Phase Error.', end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
